{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COE379L Project 3: Classical Model Implementation and Optimization\n",
        "\n",
        "## Cross-Model Comparison for News Topic Classification\n",
        "\n",
        "This notebook covers:\n",
        "- TF-IDF feature extraction (unigrams and bigrams)\n",
        "- XGBoost classifier with hyperparameter optimization\n",
        "- Support Vector Machine (SVM) implementation (LinearSVC and RBF kernel)\n",
        "- Model evaluation and performance metrics\n",
        "- Training time and inference latency measurement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import warnings\n",
        "import sys\n",
        "from datetime import datetime\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Try to import tqdm for progress bars, fallback to simple progress if not available\n",
        "try:\n",
        "    from tqdm import tqdm\n",
        "    HAS_TQDM = True\n",
        "except ImportError:\n",
        "    HAS_TQDM = False\n",
        "    print(\"Note: tqdm not available. Using simple progress tracking.\")\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, \n",
        "    f1_score, \n",
        "    log_loss, \n",
        "    confusion_matrix, \n",
        "    classification_report\n",
        ")\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Set style for visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded preprocessed data from CSV files\n",
            "Training samples: 120,000\n",
            "Test samples: 7,600\n",
            "\n",
            "Class distribution (training):\n",
            "label\n",
            "0    30000\n",
            "1    30000\n",
            "2    30000\n",
            "3    30000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "X_train shape: (120000,)\n",
            "y_train shape: (120000,)\n",
            "X_test shape: (7600,)\n",
            "y_test shape: (7600,)\n"
          ]
        }
      ],
      "source": [
        "# Load preprocessed data from the EDA notebook\n",
        "# If data files don't exist, we'll load from Hugging Face and preprocess\n",
        "import os\n",
        "\n",
        "if os.path.exists('data/train_processed.csv') and os.path.exists('data/test_processed.csv'):\n",
        "    train_df = pd.read_csv('data/train_processed.csv')\n",
        "    test_df = pd.read_csv('data/test_processed.csv')\n",
        "    print(\"Loaded preprocessed data from CSV files\")\n",
        "else:\n",
        "    # Fallback: Load and preprocess from Hugging Face\n",
        "    from datasets import load_dataset\n",
        "    \n",
        "    print(\"Loading data from Hugging Face...\")\n",
        "    dataset = load_dataset(\"ag_news\")\n",
        "    train_df = pd.DataFrame(dataset['train'])\n",
        "    test_df = pd.DataFrame(dataset['test'])\n",
        "    \n",
        "    # Note: AG News dataset has a single 'text' field that already contains title and description\n",
        "    # The format is typically \"Title. Description\" - we'll use it directly as combined_text\n",
        "    train_df['combined_text'] = train_df['text'].astype(str).str.strip()\n",
        "    test_df['combined_text'] = test_df['text'].astype(str).str.strip()\n",
        "    \n",
        "    # Keep only necessary columns\n",
        "    train_df = train_df[['label', 'combined_text']]\n",
        "    test_df = test_df[['label', 'combined_text']]\n",
        "\n",
        "print(f\"Training samples: {len(train_df):,}\")\n",
        "print(f\"Test samples: {len(test_df):,}\")\n",
        "print(f\"\\nClass distribution (training):\")\n",
        "print(train_df['label'].value_counts().sort_index())\n",
        "\n",
        "# Prepare features and labels\n",
        "X_train = train_df['combined_text'].values\n",
        "y_train = train_df['label'].values\n",
        "X_test = test_df['combined_text'].values\n",
        "y_test = test_df['label'].values\n",
        "\n",
        "print(f\"\\nX_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. TF-IDF Feature Extraction\n",
        "\n",
        "According to the project requirements, we need to generate high-dimensional sparse vector representations using unigrams and bigrams.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing TF-IDF vectorizer...\n",
            "Fitting TF-IDF on training data...\n",
            "Transforming test data...\n",
            "\n",
            "TF-IDF Feature Extraction Complete!\n",
            "Training TF-IDF fit time: 6.33 seconds\n",
            "Training features shape: (120000, 50000)\n",
            "Test features shape: (7600, 50000)\n",
            "Number of features: 50,000\n",
            "Sparsity: 99.95%\n"
          ]
        }
      ],
      "source": [
        "# Initialize TF-IDF vectorizer with unigrams and bigrams\n",
        "# Using max_features to limit dimensionality for computational efficiency\n",
        "# Adjust max_features based on available memory and computational resources\n",
        "print(\"Initializing TF-IDF vectorizer...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),  # Unigrams and bigrams\n",
        "    max_features=50000,  # Limit to top 50k features for efficiency\n",
        "    min_df=2,            # Ignore terms that appear in fewer than 2 documents\n",
        "    max_df=0.95,         # Ignore terms that appear in more than 95% of documents\n",
        "    sublinear_tf=True,   # Apply sublinear tf scaling (1 + log(tf))\n",
        "    stop_words='english' # Remove English stop words\n",
        ")\n",
        "\n",
        "# Fit and transform training data\n",
        "print(\"Fitting TF-IDF on training data...\")\n",
        "start_time = time.time()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_fit_time = time.time() - start_time\n",
        "\n",
        "# Transform test data\n",
        "print(\"Transforming test data...\")\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"\\nTF-IDF Feature Extraction Complete!\")\n",
        "print(f\"Training TF-IDF fit time: {tfidf_fit_time:.2f} seconds\")\n",
        "print(f\"Training features shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Test features shape: {X_test_tfidf.shape}\")\n",
        "print(f\"Number of features: {X_train_tfidf.shape[1]:,}\")\n",
        "print(f\"Sparsity: {(1.0 - X_train_tfidf.nnz / (X_train_tfidf.shape[0] * X_train_tfidf.shape[1])) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Helper Functions for Model Evaluation\n",
        "\n",
        "We'll create functions to evaluate models and measure training/inference times.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helper functions defined!\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    \"\"\"\n",
        "    Evaluate a trained model and return metrics.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        X_test: Test features\n",
        "        y_test: Test labels\n",
        "        model_name: Name of the model for display\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with metrics\n",
        "    \"\"\"\n",
        "    # Predictions\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    inference_time = time.time() - start_time\n",
        "    \n",
        "    # Probabilities (for log loss)\n",
        "    try:\n",
        "        y_pred_proba = model.predict_proba(X_test)\n",
        "    except:\n",
        "        # Some models might not have predict_proba\n",
        "        y_pred_proba = None\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "    \n",
        "    log_loss_score = None\n",
        "    if y_pred_proba is not None:\n",
        "        log_loss_score = log_loss(y_test, y_pred_proba)\n",
        "    \n",
        "    # Inference latency per 1000 samples\n",
        "    num_samples = len(X_test)\n",
        "    inference_latency_per_1k = (inference_time / num_samples) * 1000\n",
        "    \n",
        "    results = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1_macro,\n",
        "        'log_loss': log_loss_score,\n",
        "        'inference_time': inference_time,\n",
        "        'inference_latency_per_1k': inference_latency_per_1k,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }\n",
        "    \n",
        "    return results\n",
        "\n",
        "def measure_inference_latency(model, X_test, num_samples=1000):\n",
        "    \"\"\"\n",
        "    Measure inference latency for a specific number of samples.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        X_test: Test features\n",
        "        num_samples: Number of samples to test (default 1000)\n",
        "    \n",
        "    Returns:\n",
        "        Time taken for inference\n",
        "    \"\"\"\n",
        "    # Sample random indices\n",
        "    indices = np.random.choice(len(X_test), min(num_samples, len(X_test)), replace=False)\n",
        "    X_sample = X_test[indices]\n",
        "    \n",
        "    # Warm-up\n",
        "    _ = model.predict(X_sample[:10])\n",
        "    \n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    _ = model.predict(X_sample)\n",
        "    inference_time = time.time() - start_time\n",
        "    \n",
        "    return inference_time\n",
        "\n",
        "print(\"Helper functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "XGBoost Model Training\n",
            "================================================================================\n",
            "\n",
            "Step 1: Hyperparameter tuning on subset of data...\n",
            "Using 20,000 samples for hyperparameter tuning (out of 120,000 total)...\n",
            "Converting sparse matrix to dense...\n",
            "Subset shape: (20000, 50000)\n",
            "\n",
            "Initializing XGBoost classifier...\n",
            "Running RandomizedSearchCV...\n",
            "This may take several minutes...\n",
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        }
      ],
      "source": [
        "# Initialize XGBoost classifier\n",
        "# Note: XGBoost works better with dense matrices, but can handle sparse\n",
        "# For large sparse matrices, we'll convert to dense for better performance\n",
        "print(\"=\" * 80)\n",
        "print(\"XGBoost Model Training\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# For computational efficiency with large sparse matrices, we'll use a subset for hyperparameter tuning\n",
        "# Then train final model on full dataset with best parameters\n",
        "print(\"\\nStep 1: Hyperparameter tuning on subset of data...\")\n",
        "\n",
        "# Use a subset for faster hyperparameter search\n",
        "# Note: Use shape[0] for sparse matrices, not len()\n",
        "num_train_samples = X_train_tfidf.shape[0]\n",
        "subset_size = min(20000, num_train_samples)  # Ensure we don't exceed available data\n",
        "print(f\"Using {subset_size:,} samples for hyperparameter tuning (out of {num_train_samples:,} total)...\")\n",
        "\n",
        "# Use random sampling with fixed seed for reproducibility\n",
        "np.random.seed(42)\n",
        "indices = np.random.choice(num_train_samples, subset_size, replace=False)\n",
        "X_train_subset = X_train_tfidf[indices]\n",
        "y_train_subset = y_train[indices]\n",
        "\n",
        "# Convert sparse matrix to dense for XGBoost\n",
        "# XGBoost can handle sparse matrices, but dense is faster for smaller subsets\n",
        "print(\"Converting sparse matrix to dense...\")\n",
        "X_train_subset_dense = X_train_subset.toarray()\n",
        "print(f\"Subset shape: {X_train_subset_dense.shape}\")\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize base model\n",
        "# Note: use_label_encoder was removed in XGBoost 2.0+\n",
        "# eval_metric='mlogloss' for multi-class classification\n",
        "print(\"\\nInitializing XGBoost classifier...\")\n",
        "xgb_base = XGBClassifier(\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='mlogloss',\n",
        "    verbosity=0  # Suppress XGBoost output during search\n",
        ")\n",
        "\n",
        "# Use RandomizedSearchCV for faster search with progress tracking\n",
        "try:\n",
        "    random_search_xgb = RandomizedSearchCV(\n",
        "        estimator=xgb_base,\n",
        "        param_distributions=param_grid_xgb,\n",
        "        n_iter=10,  # Number of parameter settings sampled\n",
        "        cv=3,        # 3-fold cross-validation\n",
        "        scoring='f1_macro',\n",
        "        n_jobs=-1,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "    \n",
        "    # Track progress during hyperparameter search\n",
        "    hyperparameter_search_time = track_randomized_search(\n",
        "        random_search_xgb, \n",
        "        X_train_subset_dense, \n",
        "        y_train_subset,\n",
        "        operation_name=\"XGBoost Hyperparameter Search\"\n",
        "    )\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error during hyperparameter search: {e}\")\n",
        "    print(\"Using default parameters instead...\")\n",
        "    # Fallback to default parameters\n",
        "    random_search_xgb = type('obj', (object,), {\n",
        "        'best_params_': {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'subsample': 1.0},\n",
        "        'best_score_': 0.0\n",
        "    })()\n",
        "    hyperparameter_search_time = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Train final XGBoost model on full dataset with best parameters\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Step 2: Training final XGBoost model on full dataset...\")\n",
        "\n",
        "# For full dataset, we'll use a sample if the dataset is too large\n",
        "# XGBoost can handle large datasets, but for memory efficiency, we might sample\n",
        "num_train_samples = X_train_tfidf.shape[0]\n",
        "full_train_size = min(50000, num_train_samples)  # Use up to 50k samples for final training\n",
        "if full_train_size < num_train_samples:\n",
        "    print(f\"Using {full_train_size:,} samples for final training (for computational efficiency)\")\n",
        "    np.random.seed(42)  # Set seed for reproducibility\n",
        "    indices_full = np.random.choice(num_train_samples, full_train_size, replace=False)\n",
        "    X_train_final = X_train_tfidf[indices_full]\n",
        "    y_train_final = y_train[indices_full]\n",
        "else:\n",
        "    X_train_final = X_train_tfidf\n",
        "    y_train_final = y_train\n",
        "\n",
        "# Convert to dense matrix\n",
        "print(\"Converting to dense matrix for XGBoost...\")\n",
        "X_train_final_dense = X_train_final.toarray()\n",
        "print(f\"Final training set shape: {X_train_final_dense.shape}\")\n",
        "\n",
        "# Create final model with best parameters\n",
        "print(f\"\\nInitializing XGBoost with best parameters: {random_search_xgb.best_params_}\")\n",
        "xgb_final = XGBClassifier(\n",
        "    **random_search_xgb.best_params_,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='mlogloss',\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "# Train final model with progress tracking\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Training Final XGBoost Model\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Training samples: {X_train_final_dense.shape[0]:,}\")\n",
        "print(f\"Features: {X_train_final_dense.shape[1]:,}\")\n",
        "print(f\"Parameters: {random_search_xgb.best_params_}\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "print(\"Training in progress...\")\n",
        "\n",
        "try:\n",
        "    xgb_final.fit(X_train_final_dense, y_train_final)\n",
        "    xgb_training_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"\\n{'─'*80}\")\n",
        "    print(f\"Training completed!\")\n",
        "    print(f\"Time: {xgb_training_time:.2f} seconds ({xgb_training_time/60:.2f} minutes)\")\n",
        "    print(f\"{'─'*80}\\n\")\n",
        "    \n",
        "    # Evaluate model\n",
        "    print(\"\\nEvaluating XGBoost model...\")\n",
        "    print(\"Converting test set to dense matrix...\")\n",
        "    X_test_dense = X_test_tfidf.toarray()\n",
        "    \n",
        "    xgb_results = evaluate_model(xgb_final, X_test_dense, y_test, \"XGBoost\")\n",
        "    \n",
        "    print(f\"\\nXGBoost Results:\")\n",
        "    print(f\"  Accuracy: {xgb_results['accuracy']:.4f}\")\n",
        "    print(f\"  Macro F1-Score: {xgb_results['f1_macro']:.4f}\")\n",
        "    print(f\"  Log Loss: {xgb_results['log_loss']:.4f}\")\n",
        "    print(f\"  Training Time: {xgb_training_time:.2f} seconds\")\n",
        "    print(f\"  Inference Latency (per 1,000 samples): {xgb_results['inference_latency_per_1k']:.4f} seconds\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error during training or evaluation: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Support Vector Machine (SVM) - LinearSVC\n",
        "\n",
        "We'll implement LinearSVC which is more efficient than SVC for large datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LinearSVC is more efficient for large sparse matrices\n",
        "print(\"=\" * 80)\n",
        "print(\"SVM LinearSVC Model Training\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Define parameter grid for LinearSVC\n",
        "param_grid_svm_linear = {\n",
        "    'C': [0.1, 1.0, 10.0, 100.0],\n",
        "    'penalty': ['l2'],\n",
        "    'loss': ['squared_hinge'],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "# Initialize base model\n",
        "svm_linear_base = LinearSVC(random_state=42, dual=False)  # dual=False for n_samples > n_features\n",
        "\n",
        "# Use RandomizedSearchCV\n",
        "print(\"Running RandomizedSearchCV for LinearSVC...\")\n",
        "start_time = time.time()\n",
        "random_search_svm_linear = RandomizedSearchCV(\n",
        "    estimator=svm_linear_base,\n",
        "    param_distributions=param_grid_svm_linear,\n",
        "    n_iter=8,\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Use subset for hyperparameter tuning\n",
        "random_search_svm_linear.fit(X_train_subset, y_train_subset)\n",
        "svm_linear_hyperparameter_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nHyperparameter search completed in {svm_linear_hyperparameter_time:.2f} seconds\")\n",
        "print(f\"Best parameters: {random_search_svm_linear.best_params_}\")\n",
        "print(f\"Best CV score: {random_search_svm_linear.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final LinearSVC model on full dataset\n",
        "print(\"\\nTraining final LinearSVC model on full dataset...\")\n",
        "\n",
        "svm_linear_final = LinearSVC(\n",
        "    **random_search_svm_linear.best_params_,\n",
        "    random_state=42,\n",
        "    dual=False\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Training Final SVM LinearSVC Model\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Training samples: {X_train_tfidf.shape[0]:,}\")\n",
        "print(f\"Features: {X_train_tfidf.shape[1]:,}\")\n",
        "print(f\"Parameters: {random_search_svm_linear.best_params_}\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(\"Training in progress...\")\n",
        "start_time = time.time()\n",
        "svm_linear_final.fit(X_train_tfidf, y_train)\n",
        "svm_linear_training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n{'─'*80}\")\n",
        "print(f\"Training completed!\")\n",
        "print(f\"Time: {svm_linear_training_time:.2f} seconds ({svm_linear_training_time/60:.2f} minutes)\")\n",
        "print(f\"{'─'*80}\\n\")\n",
        "\n",
        "# Evaluate model\n",
        "print(\"\\nEvaluating LinearSVC model...\")\n",
        "svm_linear_results = evaluate_model(svm_linear_final, X_test_tfidf, y_test, \"SVM-LinearSVC\")\n",
        "\n",
        "# LinearSVC doesn't have predict_proba by default, so log_loss will be None\n",
        "# This is expected behavior for LinearSVC\n",
        "print(f\"\\nSVM LinearSVC Results:\")\n",
        "print(f\"  Accuracy: {svm_linear_results['accuracy']:.4f}\")\n",
        "print(f\"  Macro F1-Score: {svm_linear_results['f1_macro']:.4f}\")\n",
        "print(f\"  Log Loss: {svm_linear_results['log_loss']} (LinearSVC doesn't support probability estimates)\")\n",
        "print(f\"  Training Time: {svm_linear_training_time:.2f} seconds\")\n",
        "print(f\"  Inference Latency (per 1,000 samples): {svm_linear_results['inference_latency_per_1k']:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Support Vector Machine (SVM) - RBF Kernel\n",
        "\n",
        "We'll also implement SVC with RBF kernel for comparison, though it's computationally more expensive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SVC with RBF kernel - more computationally expensive\n",
        "# We'll use a smaller subset due to computational constraints\n",
        "print(\"=\" * 80)\n",
        "print(\"SVM RBF Kernel Model Training\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Note: RBF kernel is computationally expensive. Using smaller subset for training.\")\n",
        "\n",
        "# Use smaller subset for RBF kernel\n",
        "num_train_samples = X_train_tfidf.shape[0]\n",
        "rbf_subset_size = min(10000, num_train_samples)\n",
        "print(f\"Using {rbf_subset_size:,} samples for RBF SVM training...\")\n",
        "np.random.seed(42)  # Set seed for reproducibility\n",
        "indices_rbf = np.random.choice(num_train_samples, rbf_subset_size, replace=False)\n",
        "X_train_rbf = X_train_tfidf[indices_rbf].toarray()  # RBF needs dense matrix\n",
        "y_train_rbf = y_train[indices_rbf]\n",
        "\n",
        "# Define parameter grid for RBF SVC\n",
        "param_grid_svm_rbf = {\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01]\n",
        "}\n",
        "\n",
        "# Initialize base model\n",
        "svm_rbf_base = SVC(kernel='rbf', random_state=42, probability=True)  # probability=True for predict_proba\n",
        "\n",
        "# Use RandomizedSearchCV\n",
        "print(\"Running RandomizedSearchCV for RBF SVC...\")\n",
        "start_time = time.time()\n",
        "random_search_svm_rbf = RandomizedSearchCV(\n",
        "    estimator=svm_rbf_base,\n",
        "    param_distributions=param_grid_svm_rbf,\n",
        "    n_iter=6,  # Fewer iterations due to computational cost\n",
        "    cv=3,\n",
        "    scoring='f1_macro',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "random_search_svm_rbf.fit(X_train_rbf, y_train_rbf)\n",
        "svm_rbf_hyperparameter_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nHyperparameter search completed in {svm_rbf_hyperparameter_time:.2f} seconds\")\n",
        "print(f\"Best parameters: {random_search_svm_rbf.best_params_}\")\n",
        "print(f\"Best CV score: {random_search_svm_rbf.best_score_:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final RBF SVC model\n",
        "print(\"\\nTraining final RBF SVC model...\")\n",
        "\n",
        "svm_rbf_final = SVC(\n",
        "    **random_search_svm_rbf.best_params_,\n",
        "    kernel='rbf',\n",
        "    random_state=42,\n",
        "    probability=True\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Training Final SVM RBF Model\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Training samples: {X_train_rbf.shape[0]:,}\")\n",
        "print(f\"Features: {X_train_rbf.shape[1]:,}\")\n",
        "print(f\"Parameters: {random_search_svm_rbf.best_params_}\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "print(\"Training in progress...\")\n",
        "start_time = time.time()\n",
        "svm_rbf_final.fit(X_train_rbf, y_train_rbf)\n",
        "svm_rbf_training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n{'─'*80}\")\n",
        "print(f\"Training completed!\")\n",
        "print(f\"Time: {svm_rbf_training_time:.2f} seconds ({svm_rbf_training_time/60:.2f} minutes)\")\n",
        "print(f\"{'─'*80}\\n\")\n",
        "\n",
        "# Evaluate model\n",
        "print(\"\\nEvaluating RBF SVC model...\")\n",
        "X_test_dense = X_test_tfidf.toarray()\n",
        "svm_rbf_results = evaluate_model(svm_rbf_final, X_test_dense, y_test, \"SVM-RBF\")\n",
        "\n",
        "print(f\"\\nSVM RBF Results:\")\n",
        "print(f\"  Accuracy: {svm_rbf_results['accuracy']:.4f}\")\n",
        "print(f\"  Macro F1-Score: {svm_rbf_results['f1_macro']:.4f}\")\n",
        "print(f\"  Log Loss: {svm_rbf_results['log_loss']:.4f}\")\n",
        "print(f\"  Training Time: {svm_rbf_training_time:.2f} seconds\")\n",
        "print(f\"  Inference Latency (per 1,000 samples): {svm_rbf_results['inference_latency_per_1k']:.4f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Results Summary and Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "results_summary = []\n",
        "\n",
        "# Add XGBoost results\n",
        "results_summary.append({\n",
        "    'Model': 'XGBoost',\n",
        "    'Accuracy': xgb_results['accuracy'],\n",
        "    'Macro F1-Score': xgb_results['f1_macro'],\n",
        "    'Log Loss': xgb_results['log_loss'],\n",
        "    'Training Time (s)': xgb_training_time,\n",
        "    'Inference Latency per 1k (s)': xgb_results['inference_latency_per_1k']\n",
        "})\n",
        "\n",
        "# Add LinearSVC results\n",
        "results_summary.append({\n",
        "    'Model': 'SVM-LinearSVC',\n",
        "    'Accuracy': svm_linear_results['accuracy'],\n",
        "    'Macro F1-Score': svm_linear_results['f1_macro'],\n",
        "    'Log Loss': svm_linear_results['log_loss'] if svm_linear_results['log_loss'] is not None else np.nan,\n",
        "    'Training Time (s)': svm_linear_training_time,\n",
        "    'Inference Latency per 1k (s)': svm_linear_results['inference_latency_per_1k']\n",
        "})\n",
        "\n",
        "# Add RBF SVC results\n",
        "results_summary.append({\n",
        "    'Model': 'SVM-RBF',\n",
        "    'Accuracy': svm_rbf_results['accuracy'],\n",
        "    'Macro F1-Score': svm_rbf_results['f1_macro'],\n",
        "    'Log Loss': svm_rbf_results['log_loss'],\n",
        "    'Training Time (s)': svm_rbf_training_time,\n",
        "    'Inference Latency per 1k (s)': svm_rbf_results['inference_latency_per_1k']\n",
        "})\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results_summary)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CLASSICAL MODELS - RESULTS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ensure data directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('data/classical_models_results.csv', index=False)\n",
        "print(\"\\nResults saved to data/classical_models_results.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar chart comparing F1-scores\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# F1-Score comparison\n",
        "models = results_df['Model'].values\n",
        "f1_scores = results_df['Macro F1-Score'].values\n",
        "\n",
        "axes[0].bar(models, f1_scores, color=['steelblue', 'coral', 'lightgreen'])\n",
        "axes[0].set_title('Macro F1-Score Comparison - Classical Models', fontsize=14, fontweight='bold')\n",
        "axes[0].set_ylabel('Macro F1-Score', fontsize=12)\n",
        "axes[0].set_ylim([0, 1])\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(f1_scores):\n",
        "    axes[0].text(i, v + 0.01, f'{v:.4f}', ha='center', fontweight='bold')\n",
        "\n",
        "# Training time comparison\n",
        "training_times = results_df['Training Time (s)'].values\n",
        "axes[1].bar(models, training_times, color=['steelblue', 'coral', 'lightgreen'])\n",
        "axes[1].set_title('Training Time Comparison - Classical Models', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Training Time (seconds)', fontsize=12)\n",
        "axes[1].set_yscale('log')  # Log scale for better visualization\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "for i, v in enumerate(training_times):\n",
        "    axes[1].text(i, v * 1.2, f'{v:.1f}s', ha='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "os.makedirs('data', exist_ok=True)\n",
        "plt.savefig('data/classical_models_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Visualization saved to data/classical_models_comparison.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Confusion Matrices\n",
        "\n",
        "We'll create confusion matrices for the best-performing classical model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find best model based on F1-score\n",
        "best_model_idx = results_df['Macro F1-Score'].idxmax()\n",
        "best_model_name = results_df.loc[best_model_idx, 'Model']\n",
        "\n",
        "print(f\"Best performing classical model: {best_model_name}\")\n",
        "print(f\"F1-Score: {results_df.loc[best_model_idx, 'Macro F1-Score']:.4f}\")\n",
        "\n",
        "# Get predictions for best model\n",
        "if best_model_name == 'XGBoost':\n",
        "    best_predictions = xgb_results['y_pred']\n",
        "    best_model_obj = xgb_final\n",
        "elif best_model_name == 'SVM-LinearSVC':\n",
        "    best_predictions = svm_linear_results['y_pred']\n",
        "    best_model_obj = svm_linear_final\n",
        "else:  # SVM-RBF\n",
        "    best_predictions = svm_rbf_results['y_pred']\n",
        "    best_model_obj = svm_rbf_final\n",
        "\n",
        "# Class labels\n",
        "class_labels = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, best_predictions)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_labels, yticklabels=class_labels,\n",
        "            cbar_kws={'label': 'Count'})\n",
        "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.tight_layout()\n",
        "os.makedirs('data', exist_ok=True)\n",
        "plt.savefig('data/classical_models_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Confusion matrix saved to data/classical_models_confusion_matrix.png\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, best_predictions, target_names=class_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Save Models and Results\n",
        "\n",
        "We'll save the trained models and all results for later use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save models using joblib\n",
        "import joblib\n",
        "\n",
        "# Ensure data directory exists\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "print(\"Saving models and vectorizer...\")\n",
        "\n",
        "# Save TF-IDF vectorizer\n",
        "joblib.dump(tfidf_vectorizer, 'data/tfidf_vectorizer.pkl')\n",
        "print(\"✓ TF-IDF vectorizer saved\")\n",
        "\n",
        "# Save XGBoost model\n",
        "joblib.dump(xgb_final, 'data/xgb_model.pkl')\n",
        "print(\"✓ XGBoost model saved\")\n",
        "\n",
        "# Save LinearSVC model\n",
        "joblib.dump(svm_linear_final, 'data/svm_linear_model.pkl')\n",
        "print(\"✓ SVM LinearSVC model saved\")\n",
        "\n",
        "# Save RBF SVC model\n",
        "joblib.dump(svm_rbf_final, 'data/svm_rbf_model.pkl')\n",
        "print(\"✓ SVM RBF model saved\")\n",
        "\n",
        "print(\"\\nAll models and results saved successfully!\")\n",
        "print(\"Ready for comparison with transformer models in the next notebook.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
