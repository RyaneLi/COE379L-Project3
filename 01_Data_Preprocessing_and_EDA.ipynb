{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COE379L Project 3: Data Preprocessing and Exploratory Data Analysis\n",
        "\n",
        "## Cross-Model Comparison for News Topic Classification\n",
        "\n",
        "This notebook covers:\n",
        "- Loading the AG News dataset from Hugging Face\n",
        "- Data preprocessing (combining title and description)\n",
        "- Exploratory Data Analysis (EDA)\n",
        "- Data visualization and statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Hugging Face datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Set style for visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load AG News Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading AG News dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 120000/120000 [00:00<00:00, 1756831.73 examples/s]\n",
            "Generating test split: 100%|██████████| 7600/7600 [00:00<00:00, 952254.23 examples/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 120000\n",
            "Test samples: 7600\n",
            "\n",
            "Dataset features: {'text': Value('string'), 'label': ClassLabel(names=['World', 'Sports', 'Business', 'Sci/Tech'])}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# The code below was generated by AI; see [1] in Use_of_AI.md\n",
        "# Load AG News dataset from Hugging Face\n",
        "print(\"Loading AG News dataset...\")\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "# Extract train and test splits\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "print(f\"\\nDataset features: {train_data.features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Convert to Pandas DataFrames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training DataFrame shape: (120000, 2)\n",
            "Test DataFrame shape: (7600, 2)\n",
            "\n",
            "Training DataFrame columns: ['text', 'label']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
              "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
              "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
              "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
              "4  Oil prices soar to all-time record, posing new...      2"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to pandas DataFrames for easier manipulation\n",
        "train_df = pd.DataFrame(train_data)\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "print(\"Training DataFrame shape:\", train_df.shape)\n",
        "print(\"Test DataFrame shape:\", test_df.shape)\n",
        "print(\"\\nTraining DataFrame columns:\", train_df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing: Combine Title and Description\n",
        "\n",
        "According to the project requirements, we need to combine the title and description fields into a single text input for classification consistency across all models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'title'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Github/COE379L-Project3/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'title'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Apply to both train and test sets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m train_df = \u001b[43mcombine_text_fields\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m test_df = combine_text_fields(test_df)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mText fields combined successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcombine_text_fields\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     12\u001b[39m df = df.copy()\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Combine title and text with a space separator\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m) + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m + \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtitle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.astype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Remove any extra whitespace\u001b[39;00m\n\u001b[32m     18\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mcombined_text\u001b[39m\u001b[33m'\u001b[39m].str.strip()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Github/COE379L-Project3/venv/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Github/COE379L-Project3/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'title'"
          ]
        }
      ],
      "source": [
        "# The code below was generated by AI; see [2] in Use_of_AI.md\n",
        "# Note: AG News dataset has a single 'text' field that already contains title and description\n",
        "# The format is typically \"Title. Description\" - we'll use it directly as combined_text\n",
        "def prepare_text_field(df):\n",
        "    \"\"\"\n",
        "    Prepare text field for classification.\n",
        "    The AG News dataset 'text' field already contains title and description combined.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with 'text' column\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with 'combined_text' column\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Use the text field directly as combined_text (it already contains title + description)\n",
        "    df['combined_text'] = df['text'].astype(str)\n",
        "    \n",
        "    # Remove any extra whitespace\n",
        "    df['combined_text'] = df['combined_text'].str.strip()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Apply to both train and test sets\n",
        "train_df = prepare_text_field(train_df)\n",
        "test_df = prepare_text_field(test_df)\n",
        "\n",
        "print(\"Text fields prepared successfully!\")\n",
        "print(\"\\nSample combined text:\")\n",
        "print(train_df['combined_text'].iloc[0][:200] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Dataset Overview and Class Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class labels mapping\n",
        "class_labels = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
        "\n",
        "# Add label names to DataFrames\n",
        "train_df['label_name'] = train_df['label'].map(class_labels)\n",
        "test_df['label_name'] = test_df['label'].map(class_labels)\n",
        "\n",
        "# Display class distribution\n",
        "print(\"=== Training Set Class Distribution ===\")\n",
        "train_dist = train_df['label_name'].value_counts().sort_index()\n",
        "print(train_dist)\n",
        "print(f\"\\nTotal: {len(train_df)}\")\n",
        "\n",
        "print(\"\\n=== Test Set Class Distribution ===\")\n",
        "test_dist = test_df['label_name'].value_counts().sort_index()\n",
        "print(test_dist)\n",
        "print(f\"\\nTotal: {len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Training set\n",
        "train_dist.plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "axes[0].set_title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Class', fontsize=12)\n",
        "axes[0].set_ylabel('Count', fontsize=12)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Test set\n",
        "test_dist.plot(kind='bar', ax=axes[1], color='coral')\n",
        "axes[1].set_title('Test Set Class Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Class', fontsize=12)\n",
        "axes[1].set_ylabel('Count', fontsize=12)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Text Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate text length statistics\n",
        "train_df['text_length'] = train_df['combined_text'].str.len()\n",
        "train_df['word_count'] = train_df['combined_text'].str.split().str.len()\n",
        "\n",
        "test_df['text_length'] = test_df['combined_text'].str.len()\n",
        "test_df['word_count'] = test_df['combined_text'].str.split().str.len()\n",
        "\n",
        "print(\"=== Training Set Text Statistics ===\")\n",
        "print(f\"Mean text length (characters): {train_df['text_length'].mean():.2f}\")\n",
        "print(f\"Median text length (characters): {train_df['text_length'].median():.2f}\")\n",
        "print(f\"Mean word count: {train_df['word_count'].mean():.2f}\")\n",
        "print(f\"Median word count: {train_df['word_count'].median():.2f}\")\n",
        "\n",
        "print(\"\\n=== Test Set Text Statistics ===\")\n",
        "print(f\"Mean text length (characters): {test_df['text_length'].mean():.2f}\")\n",
        "print(f\"Median text length (characters): {test_df['text_length'].median():.2f}\")\n",
        "print(f\"Mean word count: {test_df['word_count'].mean():.2f}\")\n",
        "print(f\"Median word count: {test_df['word_count'].median():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize text length distributions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Character length distribution - Training\n",
        "axes[0, 0].hist(train_df['text_length'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_title('Training Set: Character Length Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Character Count', fontsize=10)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Word count distribution - Training\n",
        "axes[0, 1].hist(train_df['word_count'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].set_title('Training Set: Word Count Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Word Count', fontsize=10)\n",
        "axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Character length distribution - Test\n",
        "axes[1, 0].hist(test_df['text_length'], bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_title('Test Set: Character Length Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Character Count', fontsize=10)\n",
        "axes[1, 0].set_ylabel('Frequency', fontsize=10)\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Word count distribution - Test\n",
        "axes[1, 1].hist(test_df['word_count'], bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_title('Test Set: Word Count Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Word Count', fontsize=10)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=10)\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sample Data Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample examples from each class\n",
        "print(\"=== Sample Examples from Each Class ===\\n\")\n",
        "\n",
        "for label, label_name in class_labels.items():\n",
        "    sample = train_df[train_df['label'] == label].iloc[0]\n",
        "    print(f\"Class: {label_name} (Label: {label})\")\n",
        "    print(f\"Text: {sample['combined_text'][:200]}...\")\n",
        "    print(f\"Word Count: {sample['word_count']}\")\n",
        "    print(\"-\" * 80)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save preprocessed data for use in other notebooks\n",
        "# Keep only essential columns: label, combined_text\n",
        "train_processed = train_df[['label', 'combined_text']].copy()\n",
        "test_processed = test_df[['label', 'combined_text']].copy()\n",
        "\n",
        "# Save to CSV files\n",
        "train_processed.to_csv('data/train_processed.csv', index=False)\n",
        "test_processed.to_csv('data/test_processed.csv', index=False)\n",
        "\n",
        "print(\"Preprocessed data saved to data/ directory!\")\n",
        "print(f\"Training samples: {len(train_processed)}\")\n",
        "print(f\"Test samples: {len(test_processed)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Dataset Summary ===\")\n",
        "print(f\"\\nTraining Set:\")\n",
        "print(f\"  - Total samples: {len(train_df):,}\")\n",
        "print(f\"  - Classes: {len(class_labels)}\")\n",
        "print(f\"  - Average text length: {train_df['text_length'].mean():.1f} characters\")\n",
        "print(f\"  - Average word count: {train_df['word_count'].mean():.1f} words\")\n",
        "\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"  - Total samples: {len(test_df):,}\")\n",
        "print(f\"  - Classes: {len(class_labels)}\")\n",
        "print(f\"  - Average text length: {test_df['text_length'].mean():.1f} characters\")\n",
        "print(f\"  - Average word count: {test_df['word_count'].mean():.1f} words\")\n",
        "\n",
        "print(\"\\n✓ Data preprocessing complete!\")\n",
        "print(\"✓ Ready for model training in subsequent notebooks.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
