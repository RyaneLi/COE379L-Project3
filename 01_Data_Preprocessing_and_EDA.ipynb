{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COE379L Project 3: Data Preprocessing and Exploratory Data Analysis\n",
        "\n",
        "## Cross-Model Comparison for News Topic Classification\n",
        "\n",
        "This notebook covers:\n",
        "- Loading the AG News dataset from Hugging Face\n",
        "- Data preprocessing (combining title and description)\n",
        "- Exploratory Data Analysis (EDA)\n",
        "- Data visualization and statistics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard library imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Hugging Face datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Set style for visualizations\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load AG News Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The code below was generated by AI; see [1] in Use_of_AI.md\n",
        "# Load AG News dataset from Hugging Face\n",
        "print(\"Loading AG News dataset...\")\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "# Extract train and test splits\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "print(f\"Training samples: {len(train_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n",
        "print(f\"\\nDataset features: {train_data.features}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Convert to Pandas DataFrames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to pandas DataFrames for easier manipulation\n",
        "train_df = pd.DataFrame(train_data)\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "print(\"Training DataFrame shape:\", train_df.shape)\n",
        "print(\"Test DataFrame shape:\", test_df.shape)\n",
        "print(\"\\nTraining DataFrame columns:\", train_df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "train_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Preprocessing: Combine Title and Description\n",
        "\n",
        "According to the project requirements, we need to combine the title and description fields into a single text input for classification consistency across all models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The code below was generated by AI; see [2] in Use_of_AI.md\n",
        "def combine_text_fields(df):\n",
        "    \"\"\"\n",
        "    Combine title and text (description) fields into a single text input.\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with 'text' and 'title' columns\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with new 'combined_text' column\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Combine title and text with a space separator\n",
        "    df['combined_text'] = df['text'].astype(str) + ' ' + df['title'].astype(str)\n",
        "    \n",
        "    # Remove any extra whitespace\n",
        "    df['combined_text'] = df['combined_text'].str.strip()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Apply to both train and test sets\n",
        "train_df = combine_text_fields(train_df)\n",
        "test_df = combine_text_fields(test_df)\n",
        "\n",
        "print(\"Text fields combined successfully!\")\n",
        "print(\"\\nSample combined text:\")\n",
        "print(train_df['combined_text'].iloc[0][:200] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Dataset Overview and Class Distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class labels mapping\n",
        "class_labels = {0: 'World', 1: 'Sports', 2: 'Business', 3: 'Sci/Tech'}\n",
        "\n",
        "# Add label names to DataFrames\n",
        "train_df['label_name'] = train_df['label'].map(class_labels)\n",
        "test_df['label_name'] = test_df['label'].map(class_labels)\n",
        "\n",
        "# Display class distribution\n",
        "print(\"=== Training Set Class Distribution ===\")\n",
        "train_dist = train_df['label_name'].value_counts().sort_index()\n",
        "print(train_dist)\n",
        "print(f\"\\nTotal: {len(train_df)}\")\n",
        "\n",
        "print(\"\\n=== Test Set Class Distribution ===\")\n",
        "test_dist = test_df['label_name'].value_counts().sort_index()\n",
        "print(test_dist)\n",
        "print(f\"\\nTotal: {len(test_df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Training set\n",
        "train_dist.plot(kind='bar', ax=axes[0], color='steelblue')\n",
        "axes[0].set_title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Class', fontsize=12)\n",
        "axes[0].set_ylabel('Count', fontsize=12)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Test set\n",
        "test_dist.plot(kind='bar', ax=axes[1], color='coral')\n",
        "axes[1].set_title('Test Set Class Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Class', fontsize=12)\n",
        "axes[1].set_ylabel('Count', fontsize=12)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Text Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate text length statistics\n",
        "train_df['text_length'] = train_df['combined_text'].str.len()\n",
        "train_df['word_count'] = train_df['combined_text'].str.split().str.len()\n",
        "\n",
        "test_df['text_length'] = test_df['combined_text'].str.len()\n",
        "test_df['word_count'] = test_df['combined_text'].str.split().str.len()\n",
        "\n",
        "print(\"=== Training Set Text Statistics ===\")\n",
        "print(f\"Mean text length (characters): {train_df['text_length'].mean():.2f}\")\n",
        "print(f\"Median text length (characters): {train_df['text_length'].median():.2f}\")\n",
        "print(f\"Mean word count: {train_df['word_count'].mean():.2f}\")\n",
        "print(f\"Median word count: {train_df['word_count'].median():.2f}\")\n",
        "\n",
        "print(\"\\n=== Test Set Text Statistics ===\")\n",
        "print(f\"Mean text length (characters): {test_df['text_length'].mean():.2f}\")\n",
        "print(f\"Median text length (characters): {test_df['text_length'].median():.2f}\")\n",
        "print(f\"Mean word count: {test_df['word_count'].mean():.2f}\")\n",
        "print(f\"Median word count: {test_df['word_count'].median():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize text length distributions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Character length distribution - Training\n",
        "axes[0, 0].hist(train_df['text_length'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 0].set_title('Training Set: Character Length Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Character Count', fontsize=10)\n",
        "axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Word count distribution - Training\n",
        "axes[0, 1].hist(train_df['word_count'], bins=50, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0, 1].set_title('Training Set: Word Count Distribution', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Word Count', fontsize=10)\n",
        "axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Character length distribution - Test\n",
        "axes[1, 0].hist(test_df['text_length'], bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
        "axes[1, 0].set_title('Test Set: Character Length Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Character Count', fontsize=10)\n",
        "axes[1, 0].set_ylabel('Frequency', fontsize=10)\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Word count distribution - Test\n",
        "axes[1, 1].hist(test_df['word_count'], bins=50, color='coral', alpha=0.7, edgecolor='black')\n",
        "axes[1, 1].set_title('Test Set: Word Count Distribution', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Word Count', fontsize=10)\n",
        "axes[1, 1].set_ylabel('Frequency', fontsize=10)\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Sample Data Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample examples from each class\n",
        "print(\"=== Sample Examples from Each Class ===\\n\")\n",
        "\n",
        "for label, label_name in class_labels.items():\n",
        "    sample = train_df[train_df['label'] == label].iloc[0]\n",
        "    print(f\"Class: {label_name} (Label: {label})\")\n",
        "    print(f\"Text: {sample['combined_text'][:200]}...\")\n",
        "    print(f\"Word Count: {sample['word_count']}\")\n",
        "    print(\"-\" * 80)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Save Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save preprocessed data for use in other notebooks\n",
        "# Keep only essential columns: label, combined_text\n",
        "train_processed = train_df[['label', 'combined_text']].copy()\n",
        "test_processed = test_df[['label', 'combined_text']].copy()\n",
        "\n",
        "# Save to CSV files\n",
        "train_processed.to_csv('data/train_processed.csv', index=False)\n",
        "test_processed.to_csv('data/test_processed.csv', index=False)\n",
        "\n",
        "print(\"Preprocessed data saved to data/ directory!\")\n",
        "print(f\"Training samples: {len(train_processed)}\")\n",
        "print(f\"Test samples: {len(test_processed)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Dataset Summary ===\")\n",
        "print(f\"\\nTraining Set:\")\n",
        "print(f\"  - Total samples: {len(train_df):,}\")\n",
        "print(f\"  - Classes: {len(class_labels)}\")\n",
        "print(f\"  - Average text length: {train_df['text_length'].mean():.1f} characters\")\n",
        "print(f\"  - Average word count: {train_df['word_count'].mean():.1f} words\")\n",
        "\n",
        "print(f\"\\nTest Set:\")\n",
        "print(f\"  - Total samples: {len(test_df):,}\")\n",
        "print(f\"  - Classes: {len(class_labels)}\")\n",
        "print(f\"  - Average text length: {test_df['text_length'].mean():.1f} characters\")\n",
        "print(f\"  - Average word count: {test_df['word_count'].mean():.1f} words\")\n",
        "\n",
        "print(\"\\n✓ Data preprocessing complete!\")\n",
        "print(\"✓ Ready for model training in subsequent notebooks.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
